---
title: "Exercises Chapter 2"
output:
  html_notebook:
  html_document:
    df_print: default
    toc: yes
  
---

# Conceptual

(@)
(a) Flexible methods should outperform inflexible methods because the large sample size prevents flexible methods from overfitting.
(b) When dealing with small samples and many predictors, flexible methods tend to overfit because they show higher variances. Therefore one should expect less flexible methods to perform better.
(c) Flexible methods will outperform inflexible methods since they are generally less biased, especially if the true relationship between predictors and response is non-linear.
(d) One might expect less flexible methods to perform better in this setting since they do not catch every bit of variance in the data and therefore provide more smoothing. Flexible methods on the other hand are likely to overfit.
    
(@)
(a) $n = 500$; $p = 3$; regression problem; inference
(b) $n = 20$; $p = 13$; classification problem; prediction
(c) $n = 52$; $p = 3$; regression problem; prediction

(@)
(a) 
```{r}
library(tidyverse)
library(magrittr)

  tibble(flexibility = 1:5,
         squared_bias = c(3, .6, 0.5, 0.49, 0.48)) %>% 
  ggplot(aes(x = flexibility, y = squared_bias)) +
  geom_smooth()
```

(b) 

(@)

(@)

(@)

(@)


# Applied
(@)
(a)
```{r}
library(ISLR)

data(College)
College %<>% as_tibble()
```
(b)
```{r}
College
```
University names are already rownames.

(c)

i.
```{r}
summary(College)
```

ii.
```{r}
pairs(College)

library(GGally)
ggpairs(College)
```

