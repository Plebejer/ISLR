Linear Model Selection and Regularization
================

\#8 In this exercise, we will generate simulated data, and will then use
this data to perform best subset selection.

1)  Use the `rnorm()` function to generate a predictor \(X\) of length
    \(n = 100\), as well as a noise vector \(\epsilon\) of length
    \(n = 100\).

2)  Generate a response vector \(Y\) of length \(n = 100\) according to
    the model \(Y = β 0 + β 1 X + β 2 X 2 + β 3 X 3 + \epsilon\), where
    \(\beta_0\) , \(\beta_1\) , \(\beta_2\) , and \(\beta_3\) are
    constants of your choice.

3)  Use the \`regsubsets() function to perform best subset selection in
    order to choose the best model containing the predictors \(X\),
    \(X_2\) , \(\ldots\) , \(X_10\). What is the best model obtained
    according to \(C_p\) , \(BIC\), and adjusted \(R_2\)? Show some
    plots to provide evidence for your answer, and report the
    coefficients of the best model obtained. Note you will need to use
    the data.frame() function to create a single data set containing
    both \(X\) and \(Y\).

4)  Repeat (c), using forward stepwise selection and also using
    backwards stepwise selection. How does your answer compare to the
    results in (c)?

5)  Now fit a lasso model to the simulated data, again using \(X\),
    \(X_2\) , \(\ldots\) , \(X_10\) as predictors. Use cross-validation
    to select the optimal value of \(\lambda\). Create plots of the
    cross-validation error as a function of \(\lambda\). Report the
    resulting coefficient estimates, and discuss the results obtained.

6)  Now generate a response vector \(Y\) according to the model
    \(Y = \beta_0 + \beta_7 X_7 + \epsilon\), and perform best subset
    selection and the lasso. Discuss the results obtained.
